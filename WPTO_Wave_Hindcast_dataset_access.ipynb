{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOE WPTO Wave Hindcast Data Access\n",
    "\n",
    "This notebook provides examples on accessing the 32-year Wave Hindcast (1979-2010) dataset with brief examples on using the data within MHKiT and the SAMs tool. This data was generated via a collaboration between Pacific Northwest National Lab, Sandia National Lab, and the National Renewable Energy Lab and is hosted from Amazon Web Services using the HDF Group's Highly Scalable Data Service (HSDS) for public access.\n",
    "\n",
    "Currently the dataset only includes the U.S. West Coast, but it will grow incrementally over the next few years to include all U.S. regions by 2022. The dataset will also be extended to span 1979-2020 (42 years) by late 2022.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "There are two major sub-datasets within the overarching dataset:\n",
    "\n",
    "1. The high-spatial-resolution dataset (hereafter the 'spatial dataset/data') spans the U.S. Exclusive Economic Zone (EEZ) with an unstructured grid that has ~200 m resolution in shallow water. The time step resolution for this spatial data is 3-hours and spans 32 years, 01/01/1979 - 12/31/2010.\n",
    "  - The spatial dataset is organized into yearly files (each file contains all variables and locations in that year) and they are located on AWS at: `/nrel/US_wave/US_wave_{year}.h5`\n",
    "  - This dataset includes the following variables (indexed by 'coordinates' (latitude and longitude), and a 'time_index'):\n",
    "    - directionality_coefficient (no units)\n",
    "    - energy_period (seconds)\n",
    "    - maximum_energy_direction (degrees true, direction from-which waves are travelling)\n",
    "    - mean_absolute_period (seconds)\n",
    "    - mean_zero-crossing_period (seconds)\n",
    "    - omni-directional_wave_power (Watts)\n",
    "    - peak_period (seconds)\n",
    "    - significant_wave_height (meters)\n",
    "    - spectral_width (no units)\n",
    "    - water_depth (meters)\n",
    "\n",
    "2. The 'virtual buoy dataset' is also available at specific locations within the large spatial domain. These virtual buoys span the same 32-years of the spatial dataset however the time resolution is 1-hour, and these data also include the wave directional spectrum.\n",
    "  - The virtual buoy dataset is located on AWS at: `/nrel/US_wave/virtual_buoy/US_virtual_buoy_{year}.h5`\n",
    "  - This dataset includes all of the variables listed above, and also includes the wave spectrum (indexed by 'time_index','frequency', 'direction', and 'coordinates'):\n",
    "    - direction_wave_spectrum (meters<sup>2</sup>/(degree*Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Configuring the HSDS service\n",
    "\n",
    "For this example to work, the packages necessary can be installed via pip:\n",
    "\n",
    "```\n",
    "$ pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Next you'll need to configure h5pyd to access the data on HSDS:\n",
    "\n",
    "```\n",
    "$ hsconfigure\n",
    "```\n",
    "\n",
    "and enter at the prompt:\n",
    "\n",
    "```\n",
    "hs_endpoint = https://developer.nrel.gov/api/hsds   \n",
    "hs_username = None   \n",
    "hs_password = None   \n",
    "hs_api_key = 3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf    \n",
    "```\n",
    "\n",
    "The example API key here is for demonstation and is rate-limited per IP. To get your own API key, visit https://developer.nrel.gov/signup/. Alternatively, you can add the above contents to the hsds configuration file: `~/.hscfg`\n",
    "\n",
    "Use [Jupyter Notebook or Jupyter Lab](https://jupyter.org) to view and modify this example notebook. For example, after following the steps above, start a jupyter notebook by:\n",
    "```\n",
    "$ jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage of the Spatial Dataset\n",
    "\n",
    "The following examples illustrate basic examples using NREL-rex to access and download parts of the WPTO Wave Hindcast dataset.\n",
    "\n",
    "Datasets are returned as Pandas objects. See the Pandas [documentation](https://pandas.pydata.org/pandas-docs/stable/) \n",
    "for more information about working with Pandas objects.\n",
    "\n",
    "We start by viewing the 'index variables' of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick View of metadata, time_index, and coordinates \n",
    "from rex import WaveX\n",
    "\n",
    "waveFile = f'/nrel/US_wave/US_wave_1990.h5'\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    meta = waves.meta          ## meta is an object that contains location information for each data point\n",
    "    print(\"meta =\", meta)\n",
    "    time_index = waves.time_index # time_index contains all of the years within the file\n",
    "    print(\"time_index =\",time_index)\n",
    "    coordinates = waves.coordinates # coordinates contains all the lat/lon pars within the dataset\n",
    "    print(\"coordinates =\",coordinates)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from a single site:\n",
    "A single lat/lon pair can be given to extract data nearest to that location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the timeseries of significant_wave_height closest to a coordinate pair\n",
    "from rex import WaveX\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    lat_lon = (44.624076,-124.280097)\n",
    "    parameters = 'significant_wave_height'\n",
    "    swh_single = waves.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from multiple sites:\n",
    "A list of latitude/longitude pairs can be passed to extract data from multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the timeseries of significant_wave_height closest to multiple coordinate pairs\n",
    "from rex import WaveX\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    lat_lon = [(44.624076,-124.280097),(43.489171,-125.152137)] # set lat_lon to a list of lat/lon pairs\n",
    "    parameters = 'significant_wave_height'\n",
    "    swh_multi = waves.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data over Multiple Years:\n",
    "The examples above return data for a single year only. To extract data over a number of years, use the `MultiYearWaveX` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate yearly significant wave height datasets into a single timeseries\n",
    "from rex import MultiYearWaveX # Yearly concatonation requires the MultiYearResource function\n",
    "\n",
    "multi_year_waves = f'/nrel/US_wave/US_wave_199*.h5' # Use wildcards to indicate what years to include.\n",
    "\n",
    "with MultiYearWaveX(multi_year_waves,hsds=True) as mYears:\n",
    "    lat_lon = (44.624076,-124.280097)\n",
    "    parameters = 'significant_wave_height'\n",
    "    swh_multi_year = mYears.get_lat_lon_df(parameters, lat_lon)\n",
    "    \n",
    "swh_multi_year\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functionality extends to multiple locations and regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate yearly significant wave height datasets for multiple llocations into a single timeseries\n",
    "from rex import MultiYearWaveX \n",
    "\n",
    "multi_year_waves = f'/nrel/US_wave/US_wave_199*.h5' \n",
    "\n",
    "with MultiYearWaveX(multi_year_waves, hsds=True) as waves:\n",
    "    lat_lon = [(44.624076,-124.280097),(43.489171,-125.152137)] # set lat_lon to a list of lat/lon pairs\n",
    "    parameters = 'significant_wave_height'\n",
    "    swh_multi = waves.get_lat_lon_df(parameters, lat_lon)\n",
    "\n",
    "swh_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage of the Virtual Buoys\n",
    "\n",
    "Virtual buoys were output from theUnSWAN model runs and contain 1-hour timestep data with directional spectrum data\n",
    "\n",
    "Virtual Buoy dataset fill names follow the convention: \"/nrel/US_wave/virtual_buoy/US_virtual_buoy_{year}.h5\"\n",
    "\n",
    "These data can be accessed using the same basic approaches described above, but using a different path that points to these data: `/nrel/US_wave/virtual_buoy/US_virtual_buoy_{year}.h5`\n",
    "\n",
    "Two examples are below, the first accessing a single year of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the metadata and time_index for the virtual buoy datasets\n",
    "from rex import WaveX\n",
    "\n",
    "vBuoy = f'/nrel/US_wave/virtual_buoy/US_virtual_buoy_1995.h5'\n",
    "\n",
    "with WaveX(vBuoy, hsds=True) as waves:\n",
    "    meta = waves.meta          ## meta is an object that contains location information for each data point\n",
    "    print(\"meta =\", meta)\n",
    "    time_index = waves.time_index # time_index contains all of the years within the file\n",
    "    print(\"time_index =\",time_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second uses `MultiYearWaveX` to get multiple years of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and concatonate multiple years of significant wave height data from teh virtual buoy dataset\n",
    "from rex import MultiYearWaveX\n",
    "\n",
    "multi_year_vBuoy = f'/nrel/US_wave/virtual_buoy/US_virtual_buoy_199*.h5' # Grab all data from the 1990s\n",
    "\n",
    "with MultiYearWaveX(multi_year_vBuoy,hsds=True) as mYears:\n",
    "    lat_lon = (44.624076,-124.280097)\n",
    "    parameters = 'significant_wave_height'\n",
    "    swh_buoy = mYears.get_lat_lon_df(parameters, lat_lon)\n",
    "    \n",
    "swh_buoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration with MHKiT\n",
    "\n",
    "Functionality to read the WPTO hindcast data is currently being integrated into [MHKiT](https://mhkit-software.github.io/MHKiT/), and will be avaiable to users soon. The following examples show how you will be able to use MHKiT to access the dataset once the functions are integrated into MHKiT. In addition to the Python functions demonstrated below, MHKiT-MATLAB functions will also be available with the same functionality.  \n",
    "\n",
    "Note: The following examples currently will NOT run on your local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing local development version of MHKiT. This code will NOT work on local machines. \n",
    "import sys\n",
    "sys.path.insert(1, '/mnt/c/Users/abharath/Documents/Projects/MHKit/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from a single site:\n",
    "A single lat/lon pair can be given to extract data nearest to that location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the timeseries of significant_wave_height closest to a coordinate pair\n",
    "from mhkit.wave import io\n",
    "\n",
    "single_year_waves = f'/nrel/US_wave/US_wave_1995.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "parameters = 'significant_wave_height'\n",
    "\n",
    "wave_singleYear = io.read_US_wave_dataset(single_year_waves,parameters,lat_lon)\n",
    "\n",
    "wave_singleYear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from multiple sites:\n",
    "A list of latitude/longitude pairs can be passed to extract data from multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the timeseries of significant_wave_height closest to multiple coordinate pairs\n",
    "from mhkit.wave import io\n",
    "\n",
    "single_year_waves = f'/nrel/US_wave/US_wave_1995.h5'\n",
    "lat_lon = [(44.624076,-124.280097),(43.489171,-125.152137)]\n",
    "parameters = 'significant_wave_height'\n",
    "\n",
    "wave_multiLocal = io.read_US_wave_dataset(single_year_waves,parameters,lat_lon)\n",
    "\n",
    "wave_multiLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data over Multiple Years:\n",
    "Data can be extracted over a number of years and concatonated directly with the MHKiT tools.\n",
    "The new multi-year object has the same functionality as a single year dataset. The datasets are concatonated into a single timeseries for convenience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and concatonate a multi-year the timeseries of significant_wave_height closest to a coordinate pair\n",
    "from mhkit.wave import io\n",
    "\n",
    "multi_year_waves = f'/nrel/US_wave/US_wave_199*.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "parameters = 'significant_wave_height'\n",
    "\n",
    "wave_multiYear = io.read_US_wave_dataset(multi_year_waves,parameters,lat_lon)\n",
    "\n",
    "wave_multiYear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way to the pervious virtual buoy examples using the rex package, Virtual buoy data can be accessed through MHKiT-Python simply by selecting the correct file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Dataset Bulk Parameters\n",
    "\n",
    "In the following example we provide a simple means to view the data from the WPTO Wave Hindcast Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull datasets from AWS\n",
    "from mhkit.wave import io\n",
    "\n",
    "dataset = f'/nrel/US_wave/US_wave_1995.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "swh_name, owp_name = 'significant_wave_height', 'omni-directional_wave_power'\n",
    "\n",
    "# First we use the MHKiT loading function to grab the datasets from AWS \n",
    "swh = io.read_US_wave_dataset(dataset,swh_name,lat_lon)\n",
    "owp = io.read_US_wave_dataset(dataset,owp_name,lat_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina'\n",
    "%matplotlib widget\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "\n",
    "host.set_xlabel(\"Time\")\n",
    "host.set_ylabel(swh_name)\n",
    "par.set_ylabel(owp_name)\n",
    "\n",
    "p1, = host.plot(swh.index, swh.values, label=swh_name)\n",
    "p2, = par.plot(owp.index, owp.values, label=owp_name)\n",
    "\n",
    "leg = plt.legend()\n",
    "\n",
    "host.yaxis.get_label().set_color(p1.get_color())\n",
    "leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "par.yaxis.get_label().set_color(p2.get_color())\n",
    "leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and Working with the Virtual Buoy Direction Wave Spectum\n",
    "\n",
    "## Capture Length and Power Matrices Calculations with MHKiT\n",
    "\n",
    "The WPTO hindcast data and MHKiT can be used to compute capture length and power matrices. The following example demonstrates this workflow using a synthetically generated power dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from numpy.random import seed, normal\n",
    "\n",
    "owp = 'omni-directional_wave_power'\n",
    "J = io.read_US_wave_dataset(single_year_waves,owp,lat_lon)\n",
    "\n",
    "# Set the random seed, to reproduce results\n",
    "seed(1)                                               \n",
    "# Generate random power values\n",
    "P = Series(normal(200, 40, J.shape[0]),index = J.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhkit.wave.performance import wave_energy_flux_matrix, capture_length, capture_length_matrix, power_matrix\n",
    "from numpy import arange\n",
    "\n",
    "Te = io.read_US_wave_dataset(single_year_waves,'energy_period',lat_lon)\n",
    "Hm0 = io.read_US_wave_dataset(single_year_waves,'significant_wave_height',lat_lon)\n",
    "\n",
    "# Calculate capture length\n",
    "L = capture_length(P, J) \n",
    "\n",
    "# Generate bins for Hm0 and Te, input format (start, stop, step_size)\n",
    "Hm0_bins = arange(0, Hm0.values.max() + .5, .5)    \n",
    "Te_bins = arange(0, Te.values.max() + 1, 1)\n",
    "\n",
    "# Create capture length matrix using a mean\n",
    "LM = capture_length_matrix(Hm0, Te, L, 'mean', Hm0_bins, Te_bins)\n",
    "# Create wave energy flux matrix using mean\n",
    "JM = wave_energy_flux_matrix(Hm0, Te, J, 'mean', Hm0_bins, Te_bins)\n",
    "\n",
    "# Create power matrix using mean\n",
    "PM = power_matrix(LM, JM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mhkit.wave.graphics import plot_matrix\n",
    "# Plot the Plot mean matrix\n",
    "ax = plot_matrix(PM)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
